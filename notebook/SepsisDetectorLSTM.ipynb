{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RohanHanda/Sepsis-Detection-Using-LSTM/blob/main/SepsisDetectorLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Imports**"
      ],
      "metadata": {
        "id": "SeqLdKV_YaCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer, Bidirectional, LSTM, Dense, Dropout, LayerNormalization, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.model_selection import train_test_split\n",
        "import glob\n",
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "id": "IKr3egyDSgoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Getting Data, Parsing and Data Preprocessing**"
      ],
      "metadata": {
        "id": "4jI-u3jGZ-hP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wget -r -np -nH --cut-dirs=3 \\\n",
        "     -A \"*.psv\" \\\n",
        "     https://physionet.org/files/challenge-2019/1.0.0/training/\n"
      ],
      "metadata": {
        "id": "2qf8Sdm8Z93Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = \"\"\n",
        "\n",
        "psv_files = glob.glob(os.path.join(DATA_DIR, \"*.psv\"))\n",
        "print(\"Number of patient files:\", len(psv_files))\n"
      ],
      "metadata": {
        "id": "gjbwiw9OaUWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FEATURES = [\n",
        "    'HR',        # Heart Rate\n",
        "    'O2Sat',     # Oxygen Saturation\n",
        "    'Temp',      # Temperature\n",
        "    'SBP',       # Systolic BP\n",
        "    'DBP',       # Diastolic BP\n",
        "    'Resp',      # Respiratory Rate\n",
        "    'MAP'        # Mean Arterial Pressure\n",
        "]\n",
        "\n",
        "TARGET = 'SepsisLabel'"
      ],
      "metadata": {
        "id": "Z8ozl--daWzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_patient_file(filepath):\n",
        "    df = pd.read_csv(filepath, sep='|')\n",
        "\n",
        "    # Keep only needed columns (some files may miss some)\n",
        "    cols = [c for c in FEATURES if c in df.columns]\n",
        "    cols.append(TARGET)\n",
        "\n",
        "    df = df[cols]\n",
        "\n",
        "    # Add patient id\n",
        "    patient_id = os.path.basename(filepath).replace(\".psv\", \"\")\n",
        "    df['patient_id'] = patient_id\n",
        "\n",
        "    # Add hour index\n",
        "    df['hour'] = np.arange(len(df))\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "2n-QI8t3aX86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_patients = []\n",
        "\n",
        "for file in psv_files:\n",
        "    try:\n",
        "        patient_df = parse_patient_file(file)\n",
        "        all_patients.append(patient_df)\n",
        "    except Exception as e:\n",
        "        print(\"Error parsing:\", file, e)\n",
        "\n",
        "full_df = pd.concat(all_patients, ignore_index=True)\n",
        "\n",
        "print(\"Final shape:\", full_df.shape)\n",
        "full_df.head()"
      ],
      "metadata": {
        "id": "b0vI5s-Raanm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_df = full_df.sort_values(['patient_id', 'hour'])\n",
        "\n",
        "# Forward fill within each patient\n",
        "full_df[FEATURES] = (\n",
        "    full_df\n",
        "    .groupby('patient_id')[FEATURES]\n",
        "    .ffill()\n",
        "    .bfill()\n",
        ")\n",
        "\n",
        "# Final fallback (rare)\n",
        "for col in FEATURES:\n",
        "    full_df[col].fillna(full_df[col].median(), inplace=True)\n",
        "\n",
        "print(full_df.isna().sum())\n"
      ],
      "metadata": {
        "id": "0-fU2Uu6acvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MIN_HOURS = 24\n",
        "\n",
        "valid_patients = (\n",
        "    full_df.groupby('patient_id')\n",
        "    .filter(lambda x: len(x) >= MIN_HOURS)\n",
        ")\n",
        "\n",
        "print(\"After filtering:\", valid_patients.shape)\n"
      ],
      "metadata": {
        "id": "OLmbvK93agtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_patients.to_csv(\"sepsis_timeseries_dataset.csv\", index=False)"
      ],
      "metadata": {
        "id": "khlMic_aai52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna()\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "df[features] = scaler.fit_transform(df[features])"
      ],
      "metadata": {
        "id": "Xt_R96IubOQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_patient_sequences(df, window=24):\n",
        "    X, y = [], []\n",
        "\n",
        "    for pid in df['patient_id'].unique():\n",
        "        patient_data = df[df['patient_id'] == pid]\n",
        "\n",
        "        values = patient_data[features].values\n",
        "        labels = patient_data[target].values\n",
        "\n",
        "        for i in range(window, len(values)):\n",
        "            X.append(values[i-window:i])\n",
        "            y.append(labels[i])\n",
        "\n",
        "    return np.array(X), np.array(y)\n"
      ],
      "metadata": {
        "id": "rn88vdU4bPSx"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WINDOW = 24\n",
        "\n",
        "X, y = create_patient_sequences(df, WINDOW)\n",
        "\n",
        "print(X.shape, y.shape)"
      ],
      "metadata": {
        "id": "Z9rXaX-VbV_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save(\"X.npy\", X)\n",
        "np.save(\"y.npy\", y)"
      ],
      "metadata": {
        "id": "9zSCd-cobYIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Attention Layer**"
      ],
      "metadata": {
        "id": "3H92WvdQbi37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ImprovedAttention(Layer):\n",
        "    \"\"\"\n",
        "    Multi-head attention with better gradient flow\n",
        "    \"\"\"\n",
        "    def __init__(self, units=32, num_heads=4):\n",
        "        super().__init__()\n",
        "        self.units = units\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.W_q = self.add_weight(\n",
        "            name=\"query_weight\",\n",
        "            shape=(input_shape[-1], self.units),\n",
        "            initializer=\"glorot_uniform\"\n",
        "        )\n",
        "        self.W_k = self.add_weight(\n",
        "            name=\"key_weight\",\n",
        "            shape=(input_shape[-1], self.units),\n",
        "            initializer=\"glorot_uniform\"\n",
        "        )\n",
        "        self.W_v = self.add_weight(\n",
        "            name=\"value_weight\",\n",
        "            shape=(input_shape[-1], self.units),\n",
        "            initializer=\"glorot_uniform\"\n",
        "        )\n",
        "\n",
        "    def call(self, x):\n",
        "        # Multi-head attention\n",
        "        Q = tf.keras.backend.dot(x, self.W_q)\n",
        "        K = tf.keras.backend.dot(x, self.W_k)\n",
        "        V = tf.keras.backend.dot(x, self.W_v)\n",
        "\n",
        "        # Scaled dot-product attention\n",
        "        scores = tf.keras.backend.batch_dot(Q, K, axes=[2, 2])\n",
        "        scores = scores / tf.math.sqrt(tf.cast(self.units, tf.float32))\n",
        "        attention_weights = tf.keras.backend.softmax(scores, axis=-1)\n",
        "\n",
        "        # Apply attention to values\n",
        "        context = tf.keras.backend.batch_dot(attention_weights, V)\n",
        "\n",
        "        # Global average pooling\n",
        "        output = tf.reduce_mean(context, axis=1)\n",
        "        return output"
      ],
      "metadata": {
        "id": "FN7OGa6QSiNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Custom Metrics**"
      ],
      "metadata": {
        "id": "D0PJYKZ0br6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def focal_loss(alpha=0.25, gamma=2.0):\n",
        "    \"\"\"\n",
        "    Focal loss focuses training on hard examples\n",
        "    Better than standard cross-entropy for imbalanced data\n",
        "    \"\"\"\n",
        "    def loss(y_true, y_pred):\n",
        "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
        "\n",
        "        # Compute focal loss\n",
        "        pt = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n",
        "        focal_weight = K.pow(1 - pt, gamma)\n",
        "\n",
        "        # Cross entropy\n",
        "        ce = -y_true * K.log(y_pred) - (1 - y_true) * K.log(1 - y_pred)\n",
        "\n",
        "        # Apply focal weight and alpha\n",
        "        loss_val = alpha * focal_weight * ce\n",
        "\n",
        "        return K.mean(loss_val)\n",
        "\n",
        "    return loss"
      ],
      "metadata": {
        "id": "5RERRbyKSp5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class F1Score(tf.keras.metrics.Metric):\n",
        "    def __init__(self, name='f1_score', **kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.precision_metric = tf.keras.metrics.Precision()\n",
        "        self.recall_metric = tf.keras.metrics.Recall()\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        self.precision_metric.update_state(y_true, y_pred, sample_weight)\n",
        "        self.recall_metric.update_state(y_true, y_pred, sample_weight)\n",
        "\n",
        "    def result(self):\n",
        "        p = self.precision_metric.result()\n",
        "        r = self.recall_metric.result()\n",
        "        return 2 * ((p * r) / (p + r + K.epsilon()))\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.precision_metric.reset_state()\n",
        "        self.recall_metric.reset_state()"
      ],
      "metadata": {
        "id": "DN2VcJeDSvCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Building**"
      ],
      "metadata": {
        "id": "A1bkxNbcbwic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_improved_model(timesteps, features, lstm_units=[128, 64],\n",
        "                         attention_units=64, dropout_rate=0.3):\n",
        "    \"\"\"\n",
        "    Improved architecture with:\n",
        "    - Bidirectional LSTM for better temporal understanding\n",
        "    - Layer normalization for stable training\n",
        "    - Skip connections\n",
        "    - Better regularization\n",
        "    \"\"\"\n",
        "    i = tf.keras.Input(shape=(timesteps, features))\n",
        "\n",
        "    # First Bidirectional LSTM with layer norm\n",
        "    x = Bidirectional(LSTM(lstm_units[0], return_sequences=True))(i)\n",
        "    x = LayerNormalization()(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "\n",
        "    # Second Bidirectional LSTM\n",
        "    x = Bidirectional(LSTM(lstm_units[1], return_sequences=True))(x)\n",
        "    x = LayerNormalization()(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "\n",
        "    # Attention mechanism\n",
        "    x = ImprovedAttention(units=attention_units)(x)\n",
        "\n",
        "    # Dense layers\n",
        "    x = Dense(64, activation=\"relu\")(x)\n",
        "    x = LayerNormalization()(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "\n",
        "    x = Dense(32, activation=\"relu\")(x)\n",
        "    x = LayerNormalization()(x)\n",
        "\n",
        "    # Output layer\n",
        "    x = Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    model = Model(i, x)\n",
        "    return model"
      ],
      "metadata": {
        "id": "p4Vnbu3YSwhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train Test Split and class imbalance handling**"
      ],
      "metadata": {
        "id": "DMcHoH4Db5BN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data_properly(X, y, test_size=0.2, val_size=0.1, random_state=42):\n",
        "    \"\"\"\n",
        "    Proper data splitting to avoid data leakage\n",
        "    Assumes X is (samples, timesteps, features)\n",
        "    \"\"\"\n",
        "    # First split: train+val vs test\n",
        "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
        "    )\n",
        "\n",
        "    # Second split: train vs val\n",
        "    val_size_adjusted = val_size / (1 - test_size)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X_temp, y_temp, test_size=val_size_adjusted,\n",
        "        random_state=random_state, stratify=y_temp\n",
        "    )\n",
        "\n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test"
      ],
      "metadata": {
        "id": "LvkTDX87TWqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def oversample_minority_class(X_train, y_train, target_ratio=0.3):\n",
        "    \"\"\"\n",
        "    Simple oversampling by duplicating minority samples with noise\n",
        "    target_ratio: desired ratio of positive samples\n",
        "    \"\"\"\n",
        "    pos_idx = np.where(y_train == 1)[0]\n",
        "    neg_idx = np.where(y_train == 0)[0]\n",
        "\n",
        "    current_ratio = len(pos_idx) / len(y_train)\n",
        "\n",
        "    if current_ratio >= target_ratio:\n",
        "        return X_train, y_train\n",
        "\n",
        "    # Calculate how many positive samples we need\n",
        "    n_neg = len(neg_idx)\n",
        "    n_pos_needed = int(n_neg * target_ratio / (1 - target_ratio))\n",
        "    n_to_add = n_pos_needed - len(pos_idx)\n",
        "\n",
        "    # Oversample with slight noise\n",
        "    if n_to_add > 0:\n",
        "        sampled_idx = np.random.choice(pos_idx, size=n_to_add, replace=True)\n",
        "        X_oversampled = X_train[sampled_idx]\n",
        "\n",
        "        # Add small gaussian noise to avoid exact duplicates\n",
        "        noise = np.random.normal(0, 0.01, X_oversampled.shape)\n",
        "        X_oversampled = X_oversampled + noise\n",
        "\n",
        "        X_train = np.vstack([X_train, X_oversampled])\n",
        "        y_train = np.concatenate([y_train, np.ones(n_to_add)])\n",
        "\n",
        "        # Shuffle\n",
        "        shuffle_idx = np.random.permutation(len(y_train))\n",
        "        X_train = X_train[shuffle_idx]\n",
        "        y_train = y_train[shuffle_idx]\n",
        "\n",
        "    return X_train, y_train"
      ],
      "metadata": {
        "id": "JNwMjhhJTdwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training**"
      ],
      "metadata": {
        "id": "53eFMnbQcDC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_improved_model(X, y):\n",
        "    \"\"\"\n",
        "    Complete training pipeline\n",
        "    \"\"\"\n",
        "    # Prepare data properly\n",
        "    X_train, X_val, X_test, y_train, y_val, y_test = prepare_data_properly(X, y)\n",
        "\n",
        "    print(f\"Train shape: {X_train.shape}, Positive ratio: {y_train.mean():.4f}\")\n",
        "    print(f\"Val shape: {X_val.shape}, Positive ratio: {y_val.mean():.4f}\")\n",
        "    print(f\"Test shape: {X_test.shape}, Positive ratio: {y_test.mean():.4f}\")\n",
        "\n",
        "    # Apply oversampling to training set only\n",
        "    X_train, y_train = oversample_minority_class(X_train, y_train, target_ratio=0.2)\n",
        "    print(f\"After oversampling - Train: {X_train.shape}, Positive ratio: {y_train.mean():.4f}\")\n",
        "\n",
        "    # Compute class weights for remaining imbalance\n",
        "    classes = np.array([0, 1])\n",
        "    class_weights_array = compute_class_weight(\n",
        "        class_weight=\"balanced\",\n",
        "        classes=classes,\n",
        "        y=y_train\n",
        "    )\n",
        "    class_weight_dict = {0: class_weights_array[0], 1: class_weights_array[1]}\n",
        "    print(f\"Class weights: {class_weight_dict}\")\n",
        "\n",
        "    # Build model\n",
        "    timesteps = X_train.shape[1]\n",
        "    features = X_train.shape[2]\n",
        "\n",
        "    model = build_improved_model(\n",
        "        timesteps=timesteps,\n",
        "        features=features,\n",
        "        lstm_units=[128, 64],\n",
        "        attention_units=64,\n",
        "        dropout_rate=0.4\n",
        "    )\n",
        "\n",
        "    # Compile with improved loss and metrics\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "        loss=focal_loss(alpha=0.75, gamma=2.0),\n",
        "        metrics=[\n",
        "            'accuracy',\n",
        "            tf.keras.metrics.Precision(name='precision'),\n",
        "            tf.keras.metrics.Recall(name='recall'),\n",
        "            tf.keras.metrics.AUC(name='auc'),\n",
        "            F1Score()\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    # Callbacks\n",
        "    callbacks = [\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='val_auc',\n",
        "            patience=10,\n",
        "            restore_best_weights=True,\n",
        "            mode='max'\n",
        "        ),\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(\n",
        "            monitor='val_auc',\n",
        "            factor=0.5,\n",
        "            patience=5,\n",
        "            min_lr=1e-6,\n",
        "            mode='max'\n",
        "        ),\n",
        "        tf.keras.callbacks.ModelCheckpoint(\n",
        "            'best_sepsis_model.keras',\n",
        "            monitor='val_auc',\n",
        "            save_best_only=True,\n",
        "            mode='max'\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    # Train\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=50,\n",
        "        batch_size=128,\n",
        "        class_weight=class_weight_dict,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    return model, history, X_test, y_test"
      ],
      "metadata": {
        "id": "armCMDw2Tjvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation**"
      ],
      "metadata": {
        "id": "xTJjduHdcG9t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, X_test, y_test, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Comprehensive evaluation\n",
        "    \"\"\"\n",
        "    from sklearn.metrics import classification_report, roc_auc_score, average_precision_score\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "\n",
        "    # Predictions\n",
        "    y_prob = model.predict(X_test).ravel()\n",
        "    y_pred = (y_prob >= threshold).astype(int)\n",
        "\n",
        "    # Metrics\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"EVALUATION METRICS\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"\\nROC-AUC Score: {roc_auc_score(y_test, y_prob):.4f}\")\n",
        "    print(f\"PR-AUC Score: {average_precision_score(y_test, y_prob):.4f}\")\n",
        "    print(f\"\\nThreshold: {threshold}\")\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred, digits=4))\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(f\"TN: {cm[0,0]}, FP: {cm[0,1]}\")\n",
        "    print(f\"FN: {cm[1,0]}, TP: {cm[1,1]}\")\n",
        "\n",
        "    # Calculate additional metrics\n",
        "    sensitivity = cm[1,1] / (cm[1,1] + cm[1,0]) if (cm[1,1] + cm[1,0]) > 0 else 0\n",
        "    specificity = cm[0,0] / (cm[0,0] + cm[0,1]) if (cm[0,0] + cm[0,1]) > 0 else 0\n",
        "\n",
        "    print(f\"\\nSensitivity (Recall): {sensitivity:.4f}\")\n",
        "    print(f\"Specificity: {specificity:.4f}\")\n",
        "\n",
        "    return y_prob, y_pred"
      ],
      "metadata": {
        "id": "gEEdUTNMTs69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Main**"
      ],
      "metadata": {
        "id": "MqE75REPcY_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load your data\n",
        "X = np.load(\"X.npy\").reshape(644685, 24, 7)\n",
        "y = np.load(\"y.npy\")\n",
        "\n",
        "# Train model\n",
        "model, history, X_test, y_test = train_improved_model(X, y)\n",
        "\n",
        "# Evaluate\n",
        "y_prob, y_pred = evaluate_model(model, X_test, y_test, threshold=0.3)\n",
        "\n",
        "# Find optimal threshold\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_prob)\n",
        "f1_scores = 2 * (precision * recall) / (precision + recall + 1e-9)\n",
        "best_threshold = thresholds[np.argmax(f1_scores)]\n",
        "print(f\"\\nOptimal threshold: {best_threshold:.4f}\")\n",
        "\n",
        "# Re-evaluate with optimal threshold\n",
        "y_prob, y_pred = evaluate_model(model, X_test, y_test, threshold=best_threshold)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "J9LLFFwET0p7",
        "outputId": "698a0bf8-863c-43e2-d5e3-8f5e1fe74827"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (451279, 24, 7), Positive ratio: 0.0252\n",
            "Val shape: (64469, 24, 7), Positive ratio: 0.0252\n",
            "Test shape: (128937, 24, 7), Positive ratio: 0.0252\n",
            "After oversampling - Train: (549878, 24, 7), Positive ratio: 0.2000\n",
            "Class weights: {0: np.float64(0.6249991475393439), 1: np.float64(2.5000136394635146)}\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">139,264</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">164,352</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ improved_attention              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,576</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ImprovedAttention</span>)             │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m7\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m139,264\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m164,352\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ improved_attention              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m24,576\u001b[0m │\n",
              "│ (\u001b[38;5;33mImprovedAttention\u001b[0m)             │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │            \u001b[38;5;34m64\u001b[0m │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">335,425</span> (1.28 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m335,425\u001b[0m (1.28 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">335,425</span> (1.28 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m335,425\u001b[0m (1.28 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m4296/4296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 20ms/step - accuracy: 0.7893 - auc: 0.6700 - f1_score: 0.1284 - loss: 0.0975 - precision: 0.4110 - recall: 0.0784 - val_accuracy: 0.9502 - val_auc: 0.8010 - val_f1_score: 0.1685 - val_loss: 0.0407 - val_precision: 0.1455 - val_recall: 0.2000 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m4296/4296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 20ms/step - accuracy: 0.8255 - auc: 0.8403 - f1_score: 0.4356 - loss: 0.0722 - precision: 0.6080 - recall: 0.3434 - val_accuracy: 0.9309 - val_auc: 0.9276 - val_f1_score: 0.3227 - val_loss: 0.0285 - val_precision: 0.2143 - val_recall: 0.6529 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m4296/4296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 20ms/step - accuracy: 0.9039 - auc: 0.9522 - f1_score: 0.7552 - loss: 0.0431 - precision: 0.7645 - recall: 0.7462 - val_accuracy: 0.9581 - val_auc: 0.9738 - val_f1_score: 0.5022 - val_loss: 0.0191 - val_precision: 0.3583 - val_recall: 0.8394 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m4296/4296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 20ms/step - accuracy: 0.9461 - auc: 0.9829 - f1_score: 0.8665 - loss: 0.0266 - precision: 0.8592 - recall: 0.8740 - val_accuracy: 0.9651 - val_auc: 0.9858 - val_f1_score: 0.5703 - val_loss: 0.0170 - val_precision: 0.4134 - val_recall: 0.9194 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m4296/4296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 20ms/step - accuracy: 0.9651 - auc: 0.9918 - f1_score: 0.9133 - loss: 0.0184 - precision: 0.9059 - recall: 0.9209 - val_accuracy: 0.9717 - val_auc: 0.9895 - val_f1_score: 0.6224 - val_loss: 0.0139 - val_precision: 0.4690 - val_recall: 0.9249 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m4296/4296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 20ms/step - accuracy: 0.9741 - auc: 0.9950 - f1_score: 0.9357 - loss: 0.0144 - precision: 0.9287 - recall: 0.9429 - val_accuracy: 0.9752 - val_auc: 0.9930 - val_f1_score: 0.6586 - val_loss: 0.0132 - val_precision: 0.5043 - val_recall: 0.9489 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m4296/4296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 20ms/step - accuracy: 0.9795 - auc: 0.9966 - f1_score: 0.9490 - loss: 0.0116 - precision: 0.9437 - recall: 0.9544 - val_accuracy: 0.9831 - val_auc: 0.9935 - val_f1_score: 0.7376 - val_loss: 0.0101 - val_precision: 0.6065 - val_recall: 0.9409 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m4296/4296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 20ms/step - accuracy: 0.9831 - auc: 0.9975 - f1_score: 0.9579 - loss: 0.0098 - precision: 0.9551 - recall: 0.9608 - val_accuracy: 0.9839 - val_auc: 0.9923 - val_f1_score: 0.7472 - val_loss: 0.0112 - val_precision: 0.6175 - val_recall: 0.9458 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m4296/4296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 20ms/step - accuracy: 0.9851 - auc: 0.9979 - f1_score: 0.9628 - loss: 0.0089 - precision: 0.9586 - recall: 0.9670 - val_accuracy: 0.9823 - val_auc: 0.9916 - val_f1_score: 0.7298 - val_loss: 0.0117 - val_precision: 0.5931 - val_recall: 0.9483 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m4296/4296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 20ms/step - accuracy: 0.9874 - auc: 0.9984 - f1_score: 0.9685 - loss: 0.0077 - precision: 0.9656 - recall: 0.9716 - val_accuracy: 0.9876 - val_auc: 0.9943 - val_f1_score: 0.7930 - val_loss: 0.0074 - val_precision: 0.6860 - val_recall: 0.9397 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m4296/4296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 20ms/step - accuracy: 0.9883 - auc: 0.9986 - f1_score: 0.9709 - loss: 0.0072 - precision: 0.9685 - recall: 0.9732 - val_accuracy: 0.9879 - val_auc: 0.9949 - val_f1_score: 0.7982 - val_loss: 0.0081 - val_precision: 0.6873 - val_recall: 0.9520 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m4296/4296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 20ms/step - accuracy: 0.9895 - auc: 0.9988 - f1_score: 0.9739 - loss: 0.0065 - precision: 0.9715 - recall: 0.9763 - val_accuracy: 0.9889 - val_auc: 0.9959 - val_f1_score: 0.8124 - val_loss: 0.0068 - val_precision: 0.7088 - val_recall: 0.9514 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m4296/4296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 20ms/step - accuracy: 0.9904 - auc: 0.9989 - f1_score: 0.9760 - loss: 0.0062 - precision: 0.9734 - recall: 0.9785 - val_accuracy: 0.9906 - val_auc: 0.9957 - val_f1_score: 0.8348 - val_loss: 0.0067 - val_precision: 0.7464 - val_recall: 0.9471 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "\u001b[1m4296/4296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 20ms/step - accuracy: 0.9911 - auc: 0.9990 - f1_score: 0.9776 - loss: 0.0057 - precision: 0.9756 - recall: 0.9797 - val_accuracy: 0.9913 - val_auc: 0.9946 - val_f1_score: 0.8433 - val_loss: 0.0060 - val_precision: 0.7698 - val_recall: 0.9323 - learning_rate: 0.0010\n",
            "Epoch 15/50\n",
            "\u001b[1m4296/4296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 20ms/step - accuracy: 0.9919 - auc: 0.9991 - f1_score: 0.9797 - loss: 0.0053 - precision: 0.9772 - recall: 0.9821 - val_accuracy: 0.9904 - val_auc: 0.9953 - val_f1_score: 0.8345 - val_loss: 0.0067 - val_precision: 0.7406 - val_recall: 0.9557 - learning_rate: 0.0010\n",
            "Epoch 16/50\n",
            "\u001b[1m4296/4296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 20ms/step - accuracy: 0.9919 - auc: 0.9992 - f1_score: 0.9799 - loss: 0.0051 - precision: 0.9777 - recall: 0.9822 - val_accuracy: 0.9922 - val_auc: 0.9954 - val_f1_score: 0.8583 - val_loss: 0.0064 - val_precision: 0.7916 - val_recall: 0.9372 - learning_rate: 0.0010\n",
            "Epoch 17/50\n",
            "\u001b[1m4296/4296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 20ms/step - accuracy: 0.9928 - auc: 0.9993 - f1_score: 0.9821 - loss: 0.0047 - precision: 0.9804 - recall: 0.9837 - val_accuracy: 0.9921 - val_auc: 0.9951 - val_f1_score: 0.8582 - val_loss: 0.0059 - val_precision: 0.7854 - val_recall: 0.9458 - learning_rate: 0.0010\n",
            "Epoch 18/50\n",
            "\u001b[1m4296/4296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 20ms/step - accuracy: 0.9958 - auc: 0.9998 - f1_score: 0.9894 - loss: 0.0028 - precision: 0.9871 - recall: 0.9918 - val_accuracy: 0.9947 - val_auc: 0.9965 - val_f1_score: 0.8996 - val_loss: 0.0052 - val_precision: 0.8602 - val_recall: 0.9428 - learning_rate: 5.0000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m4296/4296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 20ms/step - accuracy: 0.9967 - auc: 0.9998 - f1_score: 0.9917 - loss: 0.0023 - precision: 0.9902 - recall: 0.9932 - val_accuracy: 0.9943 - val_auc: 0.9964 - val_f1_score: 0.8935 - val_loss: 0.0055 - val_precision: 0.8394 - val_recall: 0.9551 - learning_rate: 5.0000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m4296/4296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 20ms/step - accuracy: 0.9969 - auc: 0.9998 - f1_score: 0.9924 - loss: 0.0022 - precision: 0.9909 - recall: 0.9938 - val_accuracy: 0.9950 - val_auc: 0.9965 - val_f1_score: 0.9067 - val_loss: 0.0050 - val_precision: 0.8594 - val_recall: 0.9594 - learning_rate: 5.0000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m4296/4296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 20ms/step - accuracy: 0.9970 - auc: 0.9999 - f1_score: 0.9925 - loss: 0.0020 - precision: 0.9910 - recall: 0.9940 - val_accuracy: 0.9950 - val_auc: 0.9971 - val_f1_score: 0.9053 - val_loss: 0.0049 - val_precision: 0.8670 - val_recall: 0.9471 - learning_rate: 5.0000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m4296/4296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 20ms/step - accuracy: 0.9972 - auc: 0.9998 - f1_score: 0.9930 - loss: 0.0020 - precision: 0.9918 - recall: 0.9941 - val_accuracy: 0.9948 - val_auc: 0.9968 - val_f1_score: 0.9016 - val_loss: 0.0051 - val_precision: 0.8557 - val_recall: 0.9526 - learning_rate: 5.0000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m4296/4296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 20ms/step - accuracy: 0.9973 - auc: 0.9999 - f1_score: 0.9933 - loss: 0.0019 - precision: 0.9920 - recall: 0.9947 - val_accuracy: 0.9953 - val_auc: 0.9961 - val_f1_score: 0.9104 - val_loss: 0.0049 - val_precision: 0.8708 - val_recall: 0.9538 - learning_rate: 5.0000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m4296/4296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 20ms/step - accuracy: 0.9975 - auc: 0.9999 - f1_score: 0.9937 - loss: 0.0018 - precision: 0.9930 - recall: 0.9943 - val_accuracy: 0.9948 - val_auc: 0.9953 - val_f1_score: 0.9010 - val_loss: 0.0053 - val_precision: 0.8622 - val_recall: 0.9434 - learning_rate: 5.0000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m4296/4296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 20ms/step - accuracy: 0.9974 - auc: 0.9999 - f1_score: 0.9936 - loss: 0.0018 - precision: 0.9926 - recall: 0.9947 - val_accuracy: 0.9953 - val_auc: 0.9965 - val_f1_score: 0.9108 - val_loss: 0.0049 - val_precision: 0.8810 - val_recall: 0.9428 - learning_rate: 5.0000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m4296/4296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 20ms/step - accuracy: 0.9976 - auc: 0.9999 - f1_score: 0.9940 - loss: 0.0017 - precision: 0.9932 - recall: 0.9949 - val_accuracy: 0.9947 - val_auc: 0.9970 - val_f1_score: 0.8988 - val_loss: 0.0052 - val_precision: 0.8613 - val_recall: 0.9397 - learning_rate: 5.0000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m4296/4296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 20ms/step - accuracy: 0.9982 - auc: 0.9999 - f1_score: 0.9956 - loss: 0.0011 - precision: 0.9948 - recall: 0.9964 - val_accuracy: 0.9955 - val_auc: 0.9972 - val_f1_score: 0.9145 - val_loss: 0.0049 - val_precision: 0.8835 - val_recall: 0.9477 - learning_rate: 2.5000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m4296/4296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 20ms/step - accuracy: 0.9988 - auc: 0.9999 - f1_score: 0.9970 - loss: 8.2775e-04 - precision: 0.9963 - recall: 0.9976 - val_accuracy: 0.9957 - val_auc: 0.9974 - val_f1_score: 0.9164 - val_loss: 0.0050 - val_precision: 0.8988 - val_recall: 0.9348 - learning_rate: 2.5000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m4296/4296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 20ms/step - accuracy: 0.9988 - auc: 1.0000 - f1_score: 0.9969 - loss: 8.7118e-04 - precision: 0.9965 - recall: 0.9974 - val_accuracy: 0.9959 - val_auc: 0.9960 - val_f1_score: 0.9212 - val_loss: 0.0055 - val_precision: 0.8978 - val_recall: 0.9458 - learning_rate: 2.5000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m4296/4296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 20ms/step - accuracy: 0.9988 - auc: 1.0000 - f1_score: 0.9969 - loss: 8.0663e-04 - precision: 0.9967 - recall: 0.9971 - val_accuracy: 0.9961 - val_auc: 0.9967 - val_f1_score: 0.9238 - val_loss: 0.0052 - val_precision: 0.9016 - val_recall: 0.9471 - learning_rate: 2.5000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m4296/4296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 20ms/step - accuracy: 0.9989 - auc: 1.0000 - f1_score: 0.9974 - loss: 7.3056e-04 - precision: 0.9968 - recall: 0.9979 - val_accuracy: 0.9957 - val_auc: 0.9969 - val_f1_score: 0.9161 - val_loss: 0.0056 - val_precision: 0.8930 - val_recall: 0.9403 - learning_rate: 2.5000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m4296/4296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 20ms/step - accuracy: 0.9989 - auc: 1.0000 - f1_score: 0.9974 - loss: 7.2270e-04 - precision: 0.9970 - recall: 0.9978 - val_accuracy: 0.9962 - val_auc: 0.9968 - val_f1_score: 0.9264 - val_loss: 0.0049 - val_precision: 0.9083 - val_recall: 0.9452 - learning_rate: 2.5000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m4296/4296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 20ms/step - accuracy: 0.9990 - auc: 1.0000 - f1_score: 0.9974 - loss: 7.1509e-04 - precision: 0.9973 - recall: 0.9976 - val_accuracy: 0.9961 - val_auc: 0.9967 - val_f1_score: 0.9230 - val_loss: 0.0055 - val_precision: 0.9093 - val_recall: 0.9372 - learning_rate: 2.5000e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m4296/4296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 20ms/step - accuracy: 0.9993 - auc: 1.0000 - f1_score: 0.9982 - loss: 4.5790e-04 - precision: 0.9980 - recall: 0.9984 - val_accuracy: 0.9961 - val_auc: 0.9969 - val_f1_score: 0.9238 - val_loss: 0.0057 - val_precision: 0.9114 - val_recall: 0.9366 - learning_rate: 1.2500e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m4296/4296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 20ms/step - accuracy: 0.9994 - auc: 1.0000 - f1_score: 0.9985 - loss: 3.8844e-04 - precision: 0.9982 - recall: 0.9987 - val_accuracy: 0.9963 - val_auc: 0.9969 - val_f1_score: 0.9270 - val_loss: 0.0057 - val_precision: 0.9164 - val_recall: 0.9378 - learning_rate: 1.2500e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m4296/4296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 20ms/step - accuracy: 0.9995 - auc: 1.0000 - f1_score: 0.9987 - loss: 3.2414e-04 - precision: 0.9986 - recall: 0.9987 - val_accuracy: 0.9962 - val_auc: 0.9970 - val_f1_score: 0.9255 - val_loss: 0.0056 - val_precision: 0.9112 - val_recall: 0.9403 - learning_rate: 1.2500e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m4296/4296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 20ms/step - accuracy: 0.9994 - auc: 1.0000 - f1_score: 0.9986 - loss: 3.3043e-04 - precision: 0.9984 - recall: 0.9988 - val_accuracy: 0.9962 - val_auc: 0.9942 - val_f1_score: 0.9243 - val_loss: 0.0060 - val_precision: 0.9165 - val_recall: 0.9323 - learning_rate: 1.2500e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m4296/4296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 20ms/step - accuracy: 0.9995 - auc: 1.0000 - f1_score: 0.9987 - loss: 3.2928e-04 - precision: 0.9986 - recall: 0.9988 - val_accuracy: 0.9962 - val_auc: 0.9969 - val_f1_score: 0.9248 - val_loss: 0.0057 - val_precision: 0.9120 - val_recall: 0.9378 - learning_rate: 1.2500e-04\n",
            "\u001b[1m4030/4030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step\n",
            "\n",
            "==================================================\n",
            "EVALUATION METRICS\n",
            "==================================================\n",
            "\n",
            "ROC-AUC Score: 0.9954\n",
            "PR-AUC Score: 0.9634\n",
            "\n",
            "Threshold: 0.3\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9989    0.9961    0.9975    125687\n",
            "           1     0.8652    0.9575    0.9090      3250\n",
            "\n",
            "    accuracy                         0.9952    128937\n",
            "   macro avg     0.9320    0.9768    0.9533    128937\n",
            "weighted avg     0.9955    0.9952    0.9953    128937\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "TN: 125202, FP: 485\n",
            "FN: 138, TP: 3112\n",
            "\n",
            "Sensitivity (Recall): 0.9575\n",
            "Specificity: 0.9961\n",
            "\n",
            "Optimal threshold: 0.6274\n",
            "\u001b[1m4030/4030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step\n",
            "\n",
            "==================================================\n",
            "EVALUATION METRICS\n",
            "==================================================\n",
            "\n",
            "ROC-AUC Score: 0.9954\n",
            "PR-AUC Score: 0.9634\n",
            "\n",
            "Threshold: 0.6273660063743591\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9981    0.9980    0.9981    125687\n",
            "           1     0.9231    0.9268    0.9249      3250\n",
            "\n",
            "    accuracy                         0.9962    128937\n",
            "   macro avg     0.9606    0.9624    0.9615    128937\n",
            "weighted avg     0.9962    0.9962    0.9962    128937\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "TN: 125436, FP: 251\n",
            "FN: 238, TP: 3012\n",
            "\n",
            "Sensitivity (Recall): 0.9268\n",
            "Specificity: 0.9980\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"FinalModel.keras\")"
      ],
      "metadata": {
        "id": "Nd4WfkvKjVgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A6DB6l1ZjX8T"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNDhgYNke79cOGnXhkUcm8L",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}